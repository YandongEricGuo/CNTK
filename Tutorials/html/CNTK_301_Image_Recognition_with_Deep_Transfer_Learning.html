

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>CNTK 301: Image Recognition with Deep Transfer Learning &mdash; CNTK Tutorial Documentation  documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="CNTK Tutorial Documentation  documentation" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="tutindex.html" class="icon icon-home"> CNTK Tutorial Documentation
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">CNTK 301: Image Recognition with Deep Transfer Learning</a><ul>
<li><a class="reference internal" href="#Problem">Problem</a><ul>
<li><a class="reference internal" href="#Why-Transfer-Learning?">Why Transfer Learning?</a></li>
<li><a class="reference internal" href="#What-is-Transfer-Learning?">What is Transfer Learning?</a></li>
<li><a class="reference internal" href="#Data-Download">Data Download</a></li>
<li><a class="reference internal" href="#Pre-Trained-Model-(ResNet)">Pre-Trained Model (ResNet)</a></li>
<li><a class="reference internal" href="#Inspecting-pre-trained-model">Inspecting pre-trained model</a></li>
<li><a class="reference internal" href="#New-dataset">New dataset</a></li>
<li><a class="reference internal" href="#Training-the-Transfer-Learning-Model">Training the Transfer Learning Model</a></li>
<li><a class="reference internal" href="#Evaluate">Evaluate</a></li>
<li><a class="reference internal" href="#With-much-smaller-dataset">With much smaller dataset</a></li>
<li><a class="reference internal" href="#The-Known-Unknown">The Known Unknown</a></li>
<li><a class="reference internal" href="#Final-Thoughts,-and-Caveats">Final Thoughts, and Caveats</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="tutindex.html">CNTK Tutorial Documentation</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="tutindex.html">Docs</a> &raquo;</li>
        
      <li>CNTK 301: Image Recognition with Deep Transfer Learning</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="CNTK-301:-Image-Recognition-with-Deep-Transfer-Learning">
<h1>CNTK 301: Image Recognition with Deep Transfer Learning<a class="headerlink" href="#CNTK-301:-Image-Recognition-with-Deep-Transfer-Learning" title="Permalink to this headline">¶</a></h1>
<p>This hands-on tutorial shows how to use <a class="reference external" href="https://en.wikipedia.org/wiki/Inductive_transfer">Transfer
Learning</a> to take
an existing trained model and adapt it to your own specialized domain.
Note: This notebook will run only if you have GPU enabled machine.</p>
<div class="section" id="Problem">
<h2>Problem<a class="headerlink" href="#Problem" title="Permalink to this headline">¶</a></h2>
<p>You have been given a set of flower images that needs to be classified
into their respective categories. Image below shows a sampling of the
data source.</p>
<div class="figure">
<img alt="" src="http://www.cntk.ai/jup/cntk301_Flowers.jpg" />
</div>
<p>However, the number of images is far less than what is needed to train a
state-of-the-art classifier such as a <a class="reference external" href="https://github.com/KaimingHe/deep-residual-networks">Residual
Network</a>. You
have a rich annotated data set of images of natural scene images such as
shown below (courtesy <a class="reference external" href="http://cs.stanford.edu/people/karpathy/cnnembed/">t-SNE visualization
site</a>).</p>
<div class="figure">
<img alt="" src="http://www.cntk.ai/jup/cntk301_imagenet.jpg" />
</div>
<p>This tutorial introduces deep transfer learning as a means to leverage
multiple data sources to overcome data scarcity problem.</p>
<div class="section" id="Why-Transfer-Learning?">
<h3>Why Transfer Learning?<a class="headerlink" href="#Why-Transfer-Learning?" title="Permalink to this headline">¶</a></h3>
<p>As stated above, Transfer Learning is a useful technique when, for
instance, you know you need to classify incoming images into different
categories, but you do not have enough data to train a Deep Neural
Network (DNN) from scratch. Training DNNs takes a lot of data, all of it
labeled, and often you will not have that kind of data on hand. If your
problem is similar to one for which a network has already been trained,
though, you can use Transfer Learning to modify that network to your
problem with a fraction of the labeled images (we are talking tens
instead of thousands).</p>
</div>
<div class="section" id="What-is-Transfer-Learning?">
<h3>What is Transfer Learning?<a class="headerlink" href="#What-is-Transfer-Learning?" title="Permalink to this headline">¶</a></h3>
<p>With Transfer Learning, we use an existing trained model and adapt it to
our own problem. We are essentially building upon the features and
concepts that were learned during the training of the base model. With a
Convolutional DNN (ResNet_18 in this case), we are using the features
learned from ImageNet data and <em>cutting off</em> the final classification
layer, replacing it with a new dense layer that will predict the class
labels of our new domain.</p>
<p>The input to the old and the new prediction layer is the same, we simply
reuse the trained features. Then we train this modified network, either
only the new weights of the new prediction layer or all weights of the
entire network.</p>
<p>This can be used, for instance, when we have a small set of images that
are in a similar domain to an existing trained model. Training a Deep
Neural Network from scratch requires tens of thousands of images, but
training one that has already learned features in the domain you are
adapting it to requires far fewer.</p>
<p>In our case, this means adapting a network trained on ImageNet images
(dogs, cats, birds, etc.) to flowers, or sheep/wolves. However, Transfer
Learning has also been successfully used to adapt existing neural models
for translation, speech synthesis, and many other domains - it is a
convenient way to bootstrap your learning process.</p>
<p><strong>Importing CNTK and other useful libraries</strong></p>
<p>Microsoft’s Cognitive Toolkit comes in Python form as <code class="docutils literal"><span class="pre">cntk</span></code>, and
contains many useful submodules for IO, defining layers, training
models, and interrogating trained models. We will need many of these for
Transfer Learning, as well as some other common libraries for
downloading files, unpacking/unzipping them, working with the file
system, and loading matrices.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="c1"># Some of the flowers data is stored as .mat files</span>
<span class="kn">from</span> <span class="nn">scipy.io</span> <span class="kn">import</span> <span class="n">loadmat</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">tarfile</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Loat the right urlretrieve based on python version</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">urllib.request</span> <span class="kn">import</span> <span class="n">urlretrieve</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">urllib</span> <span class="kn">import</span> <span class="n">urlretrieve</span>

<span class="kn">import</span> <span class="nn">zipfile</span>

<span class="c1"># Useful for being able to dump images into the Notebook</span>
<span class="kn">import</span> <span class="nn">IPython.display</span> <span class="kn">as</span> <span class="nn">D</span>

<span class="c1"># Import CNTK and helpers</span>
<span class="kn">import</span> <span class="nn">cntk</span> <span class="kn">as</span> <span class="nn">C</span>
</pre></div>
</div>
</div>
<p>There are two run modes: - <em>Fast mode</em>: <code class="docutils literal"><span class="pre">isFast</span></code> is set to <code class="docutils literal"><span class="pre">True</span></code>.
This is the default mode for the notebooks, which means we train for
fewer iterations or train / test on limited data. This ensures
functional correctness of the notebook though the models produced are
far from what a completed training would produce.</p>
<ul class="simple">
<li><em>Slow mode</em>: We recommend the user to set this flag to <code class="docutils literal"><span class="pre">False</span></code> once
the user has gained familiarity with the notebook content and wants
to gain insight from running the notebooks for a longer period with
different parameters for training.</li>
</ul>
<p>For <em>Fast mode</em> we train the model for 100 epochs and results have low
accuracy but is good enough for development. The model yields good
accuracy after 1000-2000 epochs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">isFast</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Data-Download">
<h3>Data Download<a class="headerlink" href="#Data-Download" title="Permalink to this headline">¶</a></h3>
<p>Now, let us download our datasets. We use two datasets in this tutorial
- one containing <em>a bunch</em> of flowers images, and the other containing
<em>just a few</em> sheep and wolves. They’re described in more detail below,
but what we are doing here is just downloading and unpacking them.</p>
<p>First in the section below we check if the notebook is running under
internal test environment and if so download the data from a local
cache.</p>
<p>Additionally, in this block below, we check if we are running this
notebook in the CNTK internal test machines by looking for environment
variables defined there. We then select the right target device (GPU vs
CPU) to test this notebook. In other cases, we use CNTK’s default policy
to use the best available device (GPU, if available, else CPU).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">C</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">try_set_default_device</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="c1"># Check for an environment variable defined in CNTK&#39;s test infrastructure</span>
<span class="k">def</span> <span class="nf">is_test</span><span class="p">():</span> <span class="k">return</span> <span class="s1">&#39;CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY&#39;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span>

<span class="c1"># Select the right target device when this notebook is being tested</span>
<span class="c1"># Currently supported only for GPU</span>
<span class="c1"># Setup data environment for pre-built data sources for testing</span>
<span class="k">if</span> <span class="n">is_test</span><span class="p">():</span>
    <span class="k">if</span> <span class="s1">&#39;TEST_DEVICE&#39;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TEST_DEVICE&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;This notebook is currently not support on CPU&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">C</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">try_set_default_device</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">gpu</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="o">*</span><span class="s2">&quot;../Tests/EndToEndTests/CNTKv2Python/Examples&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)))</span>
    <span class="kn">import</span> <span class="nn">prepare_test_data</span> <span class="kn">as</span> <span class="nn">T</span>
    <span class="n">T</span><span class="o">.</span><span class="n">prepare_resnet_v1_model</span><span class="p">()</span>
    <span class="n">T</span><span class="o">.</span><span class="n">prepare_flower_data</span><span class="p">()</span>
    <span class="n">T</span><span class="o">.</span><span class="n">prepare_animals_data</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Reusing cached file C:\repos\CNTK\Examples\Image\PretrainedModels\ResNet_18.model
Reusing cached file C:\repos\CNTK\Examples\Image\DataSets\Flowers\102flowers.tgz
Reusing cached file C:\repos\CNTK\Examples\Image\DataSets\Flowers\imagelabels.mat
Reusing cached file C:\repos\CNTK\Examples\Image\DataSets\Flowers\imagelabels.mat
Reusing cached file C:\repos\CNTK\Examples\Image\DataSets\Animals\Animals.zip
</pre></div></div>
</div>
<p>Note that we are setting the data root to coincide with the CNTK
examples, so if you have run those some of the data might already exist.
Alter the data root if you would like all of the input and output data
to go elsewhere (i.e. if you have copied this notebook to your own
space). The <code class="docutils literal"><span class="pre">download_unless_exists</span></code> method will try to download
several times, but if that fails you might see an exception. It and the
<code class="docutils literal"><span class="pre">write_to_file</span></code> method both - write to files, so if the data_root is
not writeable or fills up you’ll see exceptions there.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># By default, we store data in the Examples/Image directory under CNTK</span>
<span class="c1"># If you&#39;re running this _outside_ of CNTK, consider changing this</span>
<span class="n">data_root</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;Examples&#39;</span><span class="p">,</span> <span class="s1">&#39;Image&#39;</span><span class="p">)</span>

<span class="n">datasets_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_root</span><span class="p">,</span> <span class="s1">&#39;DataSets&#39;</span><span class="p">)</span>
<span class="n">output_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;temp&#39;</span><span class="p">,</span> <span class="s1">&#39;Output&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">ensure_exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">write_to_file</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">img_paths</span><span class="p">,</span> <span class="n">img_labels</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;w+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">img_paths</span><span class="p">)):</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="se">\t</span><span class="si">%s</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">img_paths</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">img_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

<span class="k">def</span> <span class="nf">download_unless_exists</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Download the file unless it already exists, with retry. Throws if all retries fail.&#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Reusing locally cached: &#39;</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Starting download of {} to {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span>
        <span class="n">retry_cnt</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
                <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Download completed.&#39;</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">retry_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">retry_cnt</span> <span class="o">==</span> <span class="n">max_retries</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Exceeded maximum retry count, aborting.&#39;</span><span class="p">)</span>
                    <span class="k">raise</span>
                <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Failed to download, retrying.&#39;</span><span class="p">)</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">download_model</span><span class="p">(</span><span class="n">model_root</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_root</span><span class="p">,</span> <span class="s1">&#39;PretrainedModels&#39;</span><span class="p">)):</span>
    <span class="n">ensure_exists</span><span class="p">(</span><span class="n">model_root</span><span class="p">)</span>
    <span class="n">resnet18_model_uri</span> <span class="o">=</span> <span class="s1">&#39;https://www.cntk.ai/Models/ResNet/ResNet_18.model&#39;</span>
    <span class="n">resnet18_model_local</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_root</span><span class="p">,</span> <span class="s1">&#39;ResNet_18.model&#39;</span><span class="p">)</span>
    <span class="n">download_unless_exists</span><span class="p">(</span><span class="n">resnet18_model_uri</span><span class="p">,</span> <span class="n">resnet18_model_local</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">resnet18_model_local</span>

<span class="k">def</span> <span class="nf">download_flowers_dataset</span><span class="p">(</span><span class="n">dataset_root</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">datasets_path</span><span class="p">,</span> <span class="s1">&#39;Flowers&#39;</span><span class="p">)):</span>
    <span class="n">ensure_exists</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">)</span>
    <span class="n">flowers_uris</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz&#39;</span><span class="p">,</span>
        <span class="s1">&#39;http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat&#39;</span><span class="p">,</span>
        <span class="s1">&#39;http://www.robots.ox.ac.uk/~vgg/data/flowers/102/setid.mat&#39;</span>
    <span class="p">]</span>
    <span class="n">flowers_files</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;102flowers.tgz&#39;</span><span class="p">),</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;imagelabels.mat&#39;</span><span class="p">),</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;setid.mat&#39;</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">uri</span><span class="p">,</span> <span class="nb">file</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">flowers_uris</span><span class="p">,</span> <span class="n">flowers_files</span><span class="p">):</span>
        <span class="n">download_unless_exists</span><span class="p">(</span><span class="n">uri</span><span class="p">,</span> <span class="nb">file</span><span class="p">)</span>
    <span class="n">tar_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;extracted&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tar_dir</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Extracting {} to {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">flowers_files</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tar_dir</span><span class="p">))</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">tar_dir</span><span class="p">)</span>
        <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">flowers_files</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">tar_dir</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} already extracted to {}, using existing version&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">flowers_files</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tar_dir</span><span class="p">))</span>

    <span class="n">flowers_data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;data_folder&#39;</span><span class="p">:</span> <span class="n">dataset_root</span><span class="p">,</span>
        <span class="s1">&#39;training_map&#39;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;6k_img_map.txt&#39;</span><span class="p">),</span>
        <span class="s1">&#39;testing_map&#39;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;1k_img_map.txt&#39;</span><span class="p">),</span>
        <span class="s1">&#39;validation_map&#39;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;val_map.txt&#39;</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">flowers_data</span><span class="p">[</span><span class="s1">&#39;training_map&#39;</span><span class="p">]):</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Writing map files ...&#39;</span><span class="p">)</span>
        <span class="c1"># get image paths and 0-based image labels</span>
        <span class="n">image_paths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tar_dir</span><span class="p">,</span> <span class="s1">&#39;jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;*.jpg&#39;</span><span class="p">))))</span>
        <span class="n">image_labels</span> <span class="o">=</span> <span class="n">loadmat</span><span class="p">(</span><span class="n">flowers_files</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="s1">&#39;labels&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">image_labels</span> <span class="o">-=</span> <span class="mi">1</span>

        <span class="c1"># read set information from .mat file</span>
        <span class="n">setid</span> <span class="o">=</span> <span class="n">loadmat</span><span class="p">(</span><span class="n">flowers_files</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">idx_train</span> <span class="o">=</span> <span class="n">setid</span><span class="p">[</span><span class="s1">&#39;trnid&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">idx_test</span> <span class="o">=</span> <span class="n">setid</span><span class="p">[</span><span class="s1">&#39;tstid&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">idx_val</span> <span class="o">=</span> <span class="n">setid</span><span class="p">[</span><span class="s1">&#39;valid&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># Confusingly the training set contains 1k images and the test set contains 6k images</span>
        <span class="c1"># We swap them, because we want to train on more data</span>
        <span class="n">write_to_file</span><span class="p">(</span><span class="n">flowers_data</span><span class="p">[</span><span class="s1">&#39;training_map&#39;</span><span class="p">],</span> <span class="n">image_paths</span><span class="p">[</span><span class="n">idx_train</span><span class="p">],</span> <span class="n">image_labels</span><span class="p">[</span><span class="n">idx_train</span><span class="p">])</span>
        <span class="n">write_to_file</span><span class="p">(</span><span class="n">flowers_data</span><span class="p">[</span><span class="s1">&#39;testing_map&#39;</span><span class="p">],</span> <span class="n">image_paths</span><span class="p">[</span><span class="n">idx_test</span><span class="p">],</span> <span class="n">image_labels</span><span class="p">[</span><span class="n">idx_test</span><span class="p">])</span>
        <span class="n">write_to_file</span><span class="p">(</span><span class="n">flowers_data</span><span class="p">[</span><span class="s1">&#39;validation_map&#39;</span><span class="p">],</span> <span class="n">image_paths</span><span class="p">[</span><span class="n">idx_val</span><span class="p">],</span> <span class="n">image_labels</span><span class="p">[</span><span class="n">idx_val</span><span class="p">])</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Map files written, dataset download and unpack completed.&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Using cached map files.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">flowers_data</span>

<span class="k">def</span> <span class="nf">download_animals_dataset</span><span class="p">(</span><span class="n">dataset_root</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">datasets_path</span><span class="p">,</span> <span class="s1">&#39;Animals&#39;</span><span class="p">)):</span>
    <span class="n">ensure_exists</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">)</span>
    <span class="n">animals_uri</span> <span class="o">=</span> <span class="s1">&#39;https://www.cntk.ai/DataSets/Animals/Animals.zip&#39;</span>
    <span class="n">animals_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;Animals.zip&#39;</span><span class="p">)</span>
    <span class="n">download_unless_exists</span><span class="p">(</span><span class="n">animals_uri</span><span class="p">,</span> <span class="n">animals_file</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;Test&#39;</span><span class="p">)):</span>
        <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">animals_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">animals_zip</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Extracting {} to {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">animals_file</span><span class="p">,</span> <span class="n">dataset_root</span><span class="p">))</span>
            <span class="n">animals_zip</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;..&#39;</span><span class="p">))</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Extraction completed.&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Reusing previously extracted Animals data.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;training_folder&#39;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;Train&#39;</span><span class="p">),</span>
        <span class="s1">&#39;testing_folder&#39;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dataset_root</span><span class="p">,</span> <span class="s1">&#39;Test&#39;</span><span class="p">)</span>
    <span class="p">}</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Downloading flowers and animals data-set, this might take a while...&#39;</span><span class="p">)</span>
<span class="n">flowers_data</span> <span class="o">=</span> <span class="n">download_flowers_dataset</span><span class="p">()</span>
<span class="n">animals_data</span> <span class="o">=</span> <span class="n">download_animals_dataset</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;All data now available to the notebook!&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading flowers and animals data-set, this might take a while...
Reusing locally cached:  ..\Examples\Image\DataSets\Flowers\102flowers.tgz
Reusing locally cached:  ..\Examples\Image\DataSets\Flowers\imagelabels.mat
Reusing locally cached:  ..\Examples\Image\DataSets\Flowers\setid.mat
..\Examples\Image\DataSets\Flowers\102flowers.tgz already extracted to ..\Examples\Image\DataSets\Flowers\extracted, using existing version
Using cached map files.
Reusing locally cached:  ..\Examples\Image\DataSets\Animals\Animals.zip
Reusing previously extracted Animals data.
All data now available to the notebook!
</pre></div></div>
</div>
</div>
<div class="section" id="Pre-Trained-Model-(ResNet)">
<h3>Pre-Trained Model (ResNet)<a class="headerlink" href="#Pre-Trained-Model-(ResNet)" title="Permalink to this headline">¶</a></h3>
<p>For this task, we have chosen ResNet_18 as our trained model and will
it as the base model. This model will be adapted using Transfer Learning
for classification of flowers and animals. This model is a
<a class="reference external" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural
Network</a>
built using <a class="reference external" href="https://github.com/KaimingHe/deep-residual-networks">Residual
Network</a>
techniques. Convolutional Neural Networks build up layers of
convolutions, transforming an input image and distilling it down until
they start recognizing composite features, with deeper layers of
convolutions recognizing complex patterns are made possible. The author
of Keras has a <a class="reference external" href="https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html">fantastic
post</a>
where he describes how Convolutional Networks “see the world” which
gives a much more detailed explanation.</p>
<p>Residual Deep Learning is a technique that originated in Microsoft
Research and involves “passing through” the main signal of the input
data, so that the network winds up “learning” on just the residual
portions that differ between layers. This has proven, in practice, to
allow the training of much deeper networks by avoiding issues that
plague gradient descent on larger networks. These cells bypass
convolution layers and then come back in later before ReLU (see below),
but some have argued that even deeper networks can be built by avoiding
even more nonlinearities in the bypass channel. This is an area of hot
research right now, and one of the most exciting parts of Transfer
Learning is that you get to benefit from all of the improvements by just
integrating new trained models.</p>
<div class="figure" id="id1">
<img alt="A ResNet Block" src="https://adeshpande3.github.io/assets/ResNet.png" />
<p class="caption"><span class="caption-text">A ResNet Block</span></p>
</div>
<p>For visualizations of some of the deeper ResNet architectures, see
<a class="reference external" href="https://github.com/KaimingHe/deep-residual-networks">Kaiming He’s
GitHub</a> where he
links off to visualizations of 50, 101, and 152-layer architectures.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;Downloading pre-trained model. Note: this might take a while...&#39;</span><span class="p">)</span>
<span class="n">base_model_file</span> <span class="o">=</span> <span class="n">download_model</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Downloading pre-trained model complete!&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading pre-trained model. Note: this might take a while...
Reusing locally cached:  ..\Examples\Image\PretrainedModels\ResNet_18.model
Downloading pre-trained model complete!
</pre></div></div>
</div>
</div>
<div class="section" id="Inspecting-pre-trained-model">
<h3>Inspecting pre-trained model<a class="headerlink" href="#Inspecting-pre-trained-model" title="Permalink to this headline">¶</a></h3>
<p>We print out all of the layers in ResNet_18 to show you how you can
interrogate a model - to use a different model than ResNet_18 you would
just need to discover the appropriate last hidden layer and feature
layer to use. CNTK provides a convenient <code class="docutils literal"><span class="pre">get_node_outputs</span></code> method
under <code class="docutils literal"><span class="pre">cntk.graph</span></code> to allow you to dump all of the model details. We
can recognize the final hidden layer as the one before we start
computing the final classification into the 1000 ImageNet classes (so in
this case, <code class="docutils literal"><span class="pre">z.x</span></code>).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># define base model location and characteristics</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;model_file&#39;</span><span class="p">:</span> <span class="n">base_model_file</span><span class="p">,</span>
    <span class="s1">&#39;feature_node_name&#39;</span><span class="p">:</span> <span class="s1">&#39;features&#39;</span><span class="p">,</span>
    <span class="s1">&#39;last_hidden_node_name&#39;</span><span class="p">:</span> <span class="s1">&#39;z.x&#39;</span><span class="p">,</span>
    <span class="c1"># Channel Depth x Height x Width</span>
    <span class="s1">&#39;image_dims&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Print out all layers in the model</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Loading {} and printing all layers:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">base_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">]))</span>
<span class="n">node_outputs</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">get_node_outputs</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">base_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">node_outputs</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="s2">&quot;  {0} {1}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">l</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">l</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loading ..\Examples\Image\PretrainedModels\ResNet_18.model and printing all layers:
  ce ()
  errs ()
  top5Errs ()
  z (1000,)
  ce ()
  z (1000,)
  z.PlusArgs[0] (1000,)
  z.x (512, 1, 1)
  z.x.x.r (512, 7, 7)
  z.x.x.p (512, 7, 7)
  z.x.x.b (512, 7, 7)
  z.x.x.b.x.c (512, 7, 7)
  z.x.x.b.x (512, 7, 7)
  z.x.x.b.x._ (512, 7, 7)
  z.x.x.b.x._.x.c (512, 7, 7)
  z.x.x.x.r (512, 7, 7)
  z.x.x.x.p (512, 7, 7)
  z.x.x.x.b (512, 7, 7)
  z.x.x.x.b.x.c (512, 7, 7)
  z.x.x.x.b.x (512, 7, 7)
  z.x.x.x.b.x._ (512, 7, 7)
  z.x.x.x.b.x._.x.c (512, 7, 7)
  _z.x.x.x.r (512, 7, 7)
  _z.x.x.x.p (512, 7, 7)
  _z.x.x.x.b (512, 7, 7)
  _z.x.x.x.b.x.c (512, 7, 7)
  _z.x.x.x.b.x (512, 7, 7)
  _z.x.x.x.b.x._ (512, 7, 7)
  _z.x.x.x.b.x._.x.c (512, 7, 7)
  z.x.x.x.x.r (256, 14, 14)
  z.x.x.x.x.p (256, 14, 14)
  z.x.x.x.x.b (256, 14, 14)
  z.x.x.x.x.b.x.c (256, 14, 14)
  z.x.x.x.x.b.x (256, 14, 14)
  z.x.x.x.x.b.x._ (256, 14, 14)
  z.x.x.x.x.b.x._.x.c (256, 14, 14)
  z.x.x.x.x.x.r (256, 14, 14)
  z.x.x.x.x.x.p (256, 14, 14)
  z.x.x.x.x.x.b (256, 14, 14)
  z.x.x.x.x.x.b.x.c (256, 14, 14)
  z.x.x.x.x.x.b.x (256, 14, 14)
  z.x.x.x.x.x.b.x._ (256, 14, 14)
  z.x.x.x.x.x.b.x._.x.c (256, 14, 14)
  z.x.x.x.x.x.x.r (128, 28, 28)
  z.x.x.x.x.x.x.p (128, 28, 28)
  z.x.x.x.x.x.x.b (128, 28, 28)
  z.x.x.x.x.x.x.b.x.c (128, 28, 28)
  z.x.x.x.x.x.x.b.x (128, 28, 28)
  z.x.x.x.x.x.x.b.x._ (128, 28, 28)
  z.x.x.x.x.x.x.b.x._.x.c (128, 28, 28)
  z.x.x.x.x.x.x.x.r (128, 28, 28)
  z.x.x.x.x.x.x.x.p (128, 28, 28)
  z.x.x.x.x.x.x.x.b (128, 28, 28)
  z.x.x.x.x.x.x.x.b.x.c (128, 28, 28)
  z.x.x.x.x.x.x.x.b.x (128, 28, 28)
  z.x.x.x.x.x.x.x.b.x._ (128, 28, 28)
  z.x.x.x.x.x.x.x.b.x._.x.c (128, 28, 28)
  z.x.x.x.x.x.x.x.x.r (64, 56, 56)
  z.x.x.x.x.x.x.x.x.p (64, 56, 56)
  z.x.x.x.x.x.x.x.x.b (64, 56, 56)
  z.x.x.x.x.x.x.x.x.b.x.c (64, 56, 56)
  z.x.x.x.x.x.x.x.x.b.x (64, 56, 56)
  z.x.x.x.x.x.x.x.x.b.x._ (64, 56, 56)
  z.x.x.x.x.x.x.x.x.b.x._.x.c (64, 56, 56)
  z.x.x.x.x.x.x.x.x.x.r (64, 56, 56)
  z.x.x.x.x.x.x.x.x.x.p (64, 56, 56)
  z.x.x.x.x.x.x.x.x.x.b (64, 56, 56)
  z.x.x.x.x.x.x.x.x.x.b.x.c (64, 56, 56)
  z.x.x.x.x.x.x.x.x.x.b.x (64, 56, 56)
  z.x.x.x.x.x.x.x.x.x.b.x._ (64, 56, 56)
  z.x.x.x.x.x.x.x.x.x.b.x._.x.c (64, 56, 56)
  z.x.x.x.x.x.x.x.x.x (64, 56, 56)
  z.x.x.x.x.x.x.x.x.x.x (64, 112, 112)
  z.x.x.x.x.x.x.x.x.x.x._ (64, 112, 112)
  z.x.x.x.x.x.x.x.x.x.x._.x.c (64, 112, 112)
  z.x.x.x.x.x.x.x.s (128, 28, 28)
  z.x.x.x.x.x.x.x.s.x.c (128, 28, 28)
  z.x.x.x.x.x.s (256, 14, 14)
  z.x.x.x.x.x.s.x.c (256, 14, 14)
  z.x.x.x.s (512, 7, 7)
  z.x.x.x.s.x.c (512, 7, 7)
  errs ()
  top5Errs ()
</pre></div></div>
</div>
</div>
<div class="section" id="New-dataset">
<h3>New dataset<a class="headerlink" href="#New-dataset" title="Permalink to this headline">¶</a></h3>
<p>The Flowers dataset comes from the Oxford Visual Geometry Group, and
contains 102 different categories of flowers common to the UK. It has
roughly 8000 images split between train, test, and validation sets. The
<a class="reference external" href="http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html">VGG homepage for the
dataset</a>
contains more details.</p>
<p>The data comes in the form of a huge
<a class="reference external" href="https://en.wikipedia.org/wiki/Tar_(computing)">tarball</a> of images,
and two matrices in <code class="docutils literal"><span class="pre">.mat</span></code> format. These are 1-based matrices
containing label IDs and the train/test/validation split. We convert
them to 0-based labels, and write out the train, test, and validation
index files in the format CNTK expects (see <code class="docutils literal"><span class="pre">write_to_file</span></code> above) of
image/label pairs (tab-delimited, one per line).</p>
<p>Let’s take a look at some of the data we’ll be working with:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">plot_images</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">subplot_shape</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="o">*</span><span class="n">subplot_shape</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">image</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">vmin</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">flowers_image_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">flowers_data</span><span class="p">[</span><span class="s1">&#39;data_folder&#39;</span><span class="p">],</span> <span class="s1">&#39;extracted&#39;</span><span class="p">,</span> <span class="s1">&#39;jpg&#39;</span><span class="p">)</span>


<span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;08093&#39;</span><span class="p">,</span> <span class="s1">&#39;08084&#39;</span><span class="p">,</span> <span class="s1">&#39;08081&#39;</span><span class="p">,</span> <span class="s1">&#39;08058&#39;</span><span class="p">]:</span>
    <span class="n">D</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">flowers_image_dir</span><span class="p">,</span> <span class="s1">&#39;image_{}.jpg&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">image</span><span class="p">)),</span> <span class="n">width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_14_0.jpeg" src="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_14_0.jpeg" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_14_1.jpeg" src="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_14_1.jpeg" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_14_2.jpeg" src="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_14_2.jpeg" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_14_3.jpeg" src="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_14_3.jpeg" />
</div>
</div>
</div>
<div class="section" id="Training-the-Transfer-Learning-Model">
<h3>Training the Transfer Learning Model<a class="headerlink" href="#Training-the-Transfer-Learning-Model" title="Permalink to this headline">¶</a></h3>
<p>In the code below, we load up the pre-trained ResNet_18 model and clone
it, while stripping off the final <code class="docutils literal"><span class="pre">features</span></code> layer. We clone the model
so that we can re-use the same trained model multiple times, trained for
different things - it is not strictly necessary if you are just training
it for a single task, but this is why we would not use
<code class="docutils literal"><span class="pre">CloneMethod.share</span></code>, we want to learn new parameters. If
<code class="docutils literal"><span class="pre">freeze_weights</span></code> is true, we will freeze weights on all layers we
clone and only learn weights on the final new features layer. This can
often be useful if you are cloning higher up the tree (e.g., cloning
after the first convolutional layer to just get basic image features).</p>
<p>We find the final hidden layer (<code class="docutils literal"><span class="pre">z.x</span></code>) using <code class="docutils literal"><span class="pre">find_by_name</span></code>, clone
it and all of its predecessors, then attach a new <code class="docutils literal"><span class="pre">Dense</span></code> layer for
classification.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">cntk.io.transforms</span> <span class="kn">as</span> <span class="nn">xforms</span>
<span class="n">ensure_exists</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Creates a minibatch source for training or testing</span>
<span class="k">def</span> <span class="nf">create_mb_source</span><span class="p">(</span><span class="n">map_file</span><span class="p">,</span> <span class="n">image_dims</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">randomize</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span><span class="n">xforms</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="n">image_dims</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">height</span><span class="o">=</span><span class="n">image_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">channels</span><span class="o">=</span><span class="n">image_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">interpolations</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">C</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">MinibatchSource</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">ImageDeserializer</span><span class="p">(</span><span class="n">map_file</span><span class="p">,</span> <span class="n">C</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">StreamDefs</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">StreamDef</span><span class="p">(</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="n">transforms</span><span class="o">=</span><span class="n">transforms</span><span class="p">),</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">StreamDef</span><span class="p">(</span><span class="n">field</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">num_classes</span><span class="p">))),</span>
            <span class="n">randomize</span><span class="o">=</span><span class="n">randomize</span><span class="p">)</span>

<span class="c1"># Creates the network model for transfer learning</span>
<span class="k">def</span> <span class="nf">create_model</span><span class="p">(</span><span class="n">model_details</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">input_features</span><span class="p">,</span> <span class="n">new_prediction_node_name</span><span class="o">=</span><span class="s1">&#39;prediction&#39;</span><span class="p">,</span> <span class="n">freeze</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="c1"># Load the pretrained classification net and find nodes</span>
    <span class="n">base_model</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_details</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">])</span>
    <span class="n">feature_node</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">find_by_name</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">model_details</span><span class="p">[</span><span class="s1">&#39;feature_node_name&#39;</span><span class="p">])</span>
    <span class="n">last_node</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">find_by_name</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">model_details</span><span class="p">[</span><span class="s1">&#39;last_hidden_node_name&#39;</span><span class="p">])</span>

    <span class="c1"># Clone the desired layers with fixed weights</span>
    <span class="n">cloned_layers</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">combine</span><span class="p">([</span><span class="n">last_node</span><span class="o">.</span><span class="n">owner</span><span class="p">])</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span>
        <span class="n">C</span><span class="o">.</span><span class="n">CloneMethod</span><span class="o">.</span><span class="n">freeze</span> <span class="k">if</span> <span class="n">freeze</span> <span class="k">else</span> <span class="n">C</span><span class="o">.</span><span class="n">CloneMethod</span><span class="o">.</span><span class="n">clone</span><span class="p">,</span>
        <span class="p">{</span><span class="n">feature_node</span><span class="p">:</span> <span class="n">C</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;features&#39;</span><span class="p">)})</span>

    <span class="c1"># Add new dense layer for class prediction</span>
    <span class="n">feat_norm</span> <span class="o">=</span> <span class="n">input_features</span> <span class="o">-</span> <span class="n">C</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mi">114</span><span class="p">)</span>
    <span class="n">cloned_out</span> <span class="o">=</span> <span class="n">cloned_layers</span><span class="p">(</span><span class="n">feat_norm</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">new_prediction_node_name</span><span class="p">)</span> <span class="p">(</span><span class="n">cloned_out</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">z</span>
</pre></div>
</div>
</div>
<p>We will now train the model just like any other CNTK model training -
instantiating an input source (in this case a <code class="docutils literal"><span class="pre">MinibatchSource</span></code> from
our image data), defining the loss function, and training for a number
of epochs. Since we are training a multi-class classifier network, the
final layer is a cross-entropy Softmax, and the error function is
classification error - both conveniently provided by utility functions
in <code class="docutils literal"><span class="pre">cntk.ops</span></code>.</p>
<p>When training a pre-trained model, we are adapting the existing weights
to suit our domain. Since the weights are likely already close to
correct (especially for earlier layers that find more primitive
features), fewer examples and fewer epochs are typically required to get
good performance.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Trains a transfer learning model</span>
<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model_details</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">train_map_file</span><span class="p">,</span>
                <span class="n">learning_params</span><span class="p">,</span> <span class="n">max_images</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="n">learning_params</span><span class="p">[</span><span class="s1">&#39;max_epochs&#39;</span><span class="p">]</span>
    <span class="n">epoch_size</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">train_map_file</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">max_images</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">epoch_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">epoch_size</span><span class="p">,</span> <span class="n">max_images</span><span class="p">)</span>
    <span class="n">minibatch_size</span> <span class="o">=</span> <span class="n">learning_params</span><span class="p">[</span><span class="s1">&#39;mb_size&#39;</span><span class="p">]</span>

    <span class="c1"># Create the minibatch source and input variables</span>
    <span class="n">minibatch_source</span> <span class="o">=</span> <span class="n">create_mb_source</span><span class="p">(</span><span class="n">train_map_file</span><span class="p">,</span> <span class="n">model_details</span><span class="p">[</span><span class="s1">&#39;image_dims&#39;</span><span class="p">],</span> <span class="n">num_classes</span><span class="p">)</span>
    <span class="n">image_input</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">input_variable</span><span class="p">(</span><span class="n">model_details</span><span class="p">[</span><span class="s1">&#39;image_dims&#39;</span><span class="p">])</span>
    <span class="n">label_input</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">input_variable</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>

    <span class="c1"># Define mapping from reader streams to network inputs</span>
    <span class="n">input_map</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">image_input</span><span class="p">:</span> <span class="n">minibatch_source</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">],</span>
        <span class="n">label_input</span><span class="p">:</span> <span class="n">minibatch_source</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="c1"># Instantiate the transfer learning model and loss function</span>
    <span class="n">tl_model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">model_details</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">image_input</span><span class="p">,</span> <span class="n">freeze</span><span class="o">=</span><span class="n">learning_params</span><span class="p">[</span><span class="s1">&#39;freeze_weights&#39;</span><span class="p">])</span>
    <span class="n">ce</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">cross_entropy_with_softmax</span><span class="p">(</span><span class="n">tl_model</span><span class="p">,</span> <span class="n">label_input</span><span class="p">)</span>
    <span class="n">pe</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">classification_error</span><span class="p">(</span><span class="n">tl_model</span><span class="p">,</span> <span class="n">label_input</span><span class="p">)</span>

    <span class="c1"># Instantiate the trainer object</span>
    <span class="n">lr_schedule</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">learning_rate_schedule</span><span class="p">(</span><span class="n">learning_params</span><span class="p">[</span><span class="s1">&#39;lr_per_mb&#39;</span><span class="p">],</span> <span class="n">unit</span><span class="o">=</span><span class="n">C</span><span class="o">.</span><span class="n">UnitType</span><span class="o">.</span><span class="n">minibatch</span><span class="p">)</span>
    <span class="n">mm_schedule</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">momentum_schedule</span><span class="p">(</span><span class="n">learning_params</span><span class="p">[</span><span class="s1">&#39;momentum_per_mb&#39;</span><span class="p">])</span>
    <span class="n">learner</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">momentum_sgd</span><span class="p">(</span><span class="n">tl_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">lr_schedule</span><span class="p">,</span> <span class="n">mm_schedule</span><span class="p">,</span>
                           <span class="n">l2_regularization_weight</span><span class="o">=</span><span class="n">learning_params</span><span class="p">[</span><span class="s1">&#39;l2_reg_weight&#39;</span><span class="p">])</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">tl_model</span><span class="p">,</span> <span class="p">(</span><span class="n">ce</span><span class="p">,</span> <span class="n">pe</span><span class="p">),</span> <span class="n">learner</span><span class="p">)</span>

    <span class="c1"># Get minibatches of images and perform model training</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Training transfer learning model for {0} epochs (epoch_size = {1}).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">,</span> <span class="n">epoch_size</span><span class="p">))</span>
    <span class="n">C</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">log_number_of_parameters</span><span class="p">(</span><span class="n">tl_model</span><span class="p">)</span>
    <span class="n">progress_printer</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ProgressPrinter</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>       <span class="c1"># loop over epochs</span>
        <span class="n">sample_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">sample_count</span> <span class="o">&lt;</span> <span class="n">epoch_size</span><span class="p">:</span>  <span class="c1"># loop over minibatches in the epoch</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">minibatch_source</span><span class="o">.</span><span class="n">next_minibatch</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">minibatch_size</span><span class="p">,</span> <span class="n">epoch_size</span> <span class="o">-</span> <span class="n">sample_count</span><span class="p">),</span> <span class="n">input_map</span><span class="o">=</span><span class="n">input_map</span><span class="p">)</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">train_minibatch</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>                                    <span class="c1"># update model with it</span>
            <span class="n">sample_count</span> <span class="o">+=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">previous_minibatch_sample_count</span>          <span class="c1"># count samples processed so far</span>
            <span class="n">progress_printer</span><span class="o">.</span><span class="n">update_with_trainer</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">with_metric</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># log progress</span>
            <span class="k">if</span> <span class="n">sample_count</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">minibatch_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span> <span class="p">(</span><span class="s2">&quot;Processed {0} samples&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sample_count</span><span class="p">))</span>

        <span class="n">progress_printer</span><span class="o">.</span><span class="n">epoch_summary</span><span class="p">(</span><span class="n">with_metric</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tl_model</span>
</pre></div>
</div>
</div>
<p>When we evaluate the trained model on an image, we have to massage that
image into the expected format. In our case we use <code class="docutils literal"><span class="pre">Image</span></code> to load the
image from its path, resize it to the size expected by our model,
reverse the color channels (RGB to BGR), and convert to a contiguous
array along height, width, and color channels. This corresponds to the
224x224x3 flattened array on which our model was trained.</p>
<p>The model with which we are doing the evaluation has not had the Softmax
and Error layers added, so is complete up to the final feature layer. To
evaluate the image with the model, we send the input data to the
<code class="docutils literal"><span class="pre">model.eval</span></code> method, <code class="docutils literal"><span class="pre">softmax</span></code> over the results to produce
probabilities, and use Numpy’s <code class="docutils literal"><span class="pre">argmax</span></code> method to determine the
predicted class. We can then compare that against the true labels to get
the overall model accuracy.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Evaluates a single image using the re-trained model</span>
<span class="k">def</span> <span class="nf">eval_single_image</span><span class="p">(</span><span class="n">loaded_model</span><span class="p">,</span> <span class="n">image_path</span><span class="p">,</span> <span class="n">image_dims</span><span class="p">):</span>
    <span class="c1"># load and format image (resize, RGB -&gt; BGR, CHW -&gt; HWC)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">image_path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;png&quot;</span><span class="p">):</span>
            <span class="n">temp</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">))</span>
            <span class="n">temp</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">temp</span>
        <span class="n">resized</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="n">image_dims</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">image_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">Image</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">)</span>
        <span class="n">bgr_image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">resized</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
        <span class="n">hwc_format</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">rollaxis</span><span class="p">(</span><span class="n">bgr_image</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

        <span class="c1"># compute model output</span>
        <span class="n">arguments</span> <span class="o">=</span> <span class="p">{</span><span class="n">loaded_model</span><span class="o">.</span><span class="n">arguments</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="p">[</span><span class="n">hwc_format</span><span class="p">]}</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">arguments</span><span class="p">)</span>

        <span class="c1"># return softmax probabilities</span>
        <span class="n">sm</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">sm</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">except</span> <span class="n">FileNotFoundError</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Could not open (skipping file): &quot;</span><span class="p">,</span> <span class="n">image_path</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="s1">&#39;None&#39;</span><span class="p">]</span>



<span class="c1"># Evaluates an image set using the provided model</span>
<span class="k">def</span> <span class="nf">eval_test_images</span><span class="p">(</span><span class="n">loaded_model</span><span class="p">,</span> <span class="n">output_file</span><span class="p">,</span> <span class="n">test_map_file</span><span class="p">,</span> <span class="n">image_dims</span><span class="p">,</span> <span class="n">max_images</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">column_offset</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">num_images</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">test_map_file</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">max_images</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">num_images</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="n">max_images</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">isFast</span><span class="p">:</span>
        <span class="n">num_images</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span> <span class="c1">#We will run through fewer images for test run</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Evaluating model output node &#39;{0}&#39; for {1} images.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;prediction&#39;</span><span class="p">,</span> <span class="n">num_images</span><span class="p">))</span>

    <span class="n">pred_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="n">over</span><span class="o">=</span><span class="s1">&#39;raise&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_file</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">results_file</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">test_map_file</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">input_file</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">input_file</span><span class="p">:</span>
                <span class="n">tokens</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="n">img_file</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="mi">0</span> <span class="o">+</span> <span class="n">column_offset</span><span class="p">]</span>
                <span class="n">probs</span> <span class="o">=</span> <span class="n">eval_single_image</span><span class="p">(</span><span class="n">loaded_model</span><span class="p">,</span> <span class="n">img_file</span><span class="p">,</span> <span class="n">image_dims</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;None&#39;</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Eval not possible: &quot;</span><span class="p">,</span> <span class="n">img_file</span><span class="p">)</span>
                    <span class="k">continue</span>

                <span class="n">pred_count</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">true_label</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span> <span class="o">+</span> <span class="n">column_offset</span><span class="p">])</span>
                <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">predicted_label</span> <span class="o">==</span> <span class="n">true_label</span><span class="p">:</span>
                    <span class="n">correct_count</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1">#np.savetxt(results_file, probs[np.newaxis], fmt=&quot;%.3f&quot;)</span>
                <span class="k">if</span> <span class="n">pred_count</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Processed {0} samples ({1:.2%} correct)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pred_count</span><span class="p">,</span>
                                                                           <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">correct_count</span><span class="p">)</span> <span class="o">/</span> <span class="n">pred_count</span><span class="p">)))</span>
                <span class="k">if</span> <span class="n">pred_count</span> <span class="o">&gt;=</span> <span class="n">num_images</span><span class="p">:</span>
                    <span class="k">break</span>
    <span class="k">print</span> <span class="p">(</span><span class="s2">&quot;{0} of {1} prediction were correct&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">correct_count</span><span class="p">,</span> <span class="n">pred_count</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">correct_count</span><span class="p">,</span> <span class="n">pred_count</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">correct_count</span><span class="p">)</span> <span class="o">/</span> <span class="n">pred_count</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Finally, with all of these helper functions in place we can train the
model and evaluate it on our flower dataset.</p>
<p>Feel free to adjust the <code class="docutils literal"><span class="pre">learning_params</span></code> below and observe the
results. You can tweak the <code class="docutils literal"><span class="pre">max_epochs</span></code> to train for longer,
<code class="docutils literal"><span class="pre">mb_size</span></code> to adjust the size of each minibatch, or <code class="docutils literal"><span class="pre">lr_per_mb</span></code> to
play with the speed of convergence (learning rate).</p>
<p><strong>Note that if you’ve already trained the model, you will want to set
``force_retraining`` to ``True`` to force the Notebook to re-train your
model with the new parameters.</strong></p>
<p>You should see the model train and evaluate, with a final accuracy
somewhere in the realm of 94%. At this point you could choose to train
longer, or consider taking a look at the confusion matrix to determine
if certain flowers are mis-predicted at a greater rate. You could also
easily swap out to a different model and see if that performs better, or
potentially learn from an earlier point in the model architecture.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">force_retraining</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">max_training_epochs</span> <span class="o">=</span> <span class="mi">5</span> <span class="k">if</span> <span class="n">isFast</span> <span class="k">else</span> <span class="mi">20</span>

<span class="n">learning_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;max_epochs&#39;</span><span class="p">:</span> <span class="n">max_training_epochs</span><span class="p">,</span>
    <span class="s1">&#39;mb_size&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s1">&#39;lr_per_mb&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">]</span><span class="o">*</span><span class="mi">10</span> <span class="o">+</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">],</span>
    <span class="s1">&#39;momentum_per_mb&#39;</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="s1">&#39;l2_reg_weight&#39;</span><span class="p">:</span> <span class="mf">0.0005</span><span class="p">,</span>
    <span class="s1">&#39;freeze_weights&#39;</span><span class="p">:</span> <span class="bp">True</span>
<span class="p">}</span>

<span class="n">flowers_model</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;model_file&#39;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s1">&#39;FlowersTransferLearning.model&#39;</span><span class="p">),</span>
    <span class="s1">&#39;results_file&#39;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s1">&#39;FlowersPredictions.txt&#39;</span><span class="p">),</span>
    <span class="s1">&#39;num_classes&#39;</span><span class="p">:</span> <span class="mi">102</span>
<span class="p">}</span>

<span class="c1"># Train only if no model exists yet or if force_retraining is set to True</span>
<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">flowers_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">])</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">force_retraining</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Loading existing model from </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">flowers_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">])</span>
    <span class="n">trained_model</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">flowers_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">trained_model</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span>
                                <span class="n">flowers_model</span><span class="p">[</span><span class="s1">&#39;num_classes&#39;</span><span class="p">],</span> <span class="n">flowers_data</span><span class="p">[</span><span class="s1">&#39;training_map&#39;</span><span class="p">],</span>
                                <span class="n">learning_params</span><span class="p">)</span>
    <span class="n">trained_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">flowers_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Stored trained model at </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">flowers_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Training transfer learning model for 5 epochs (epoch_size = 6149).
Training 52326 parameters in 2 parameter tensors.
Processed 5000 samples
Finished Epoch[1 of 5]: [Training] loss = 1.887996 * 6149, metric = 41.52% * 6149 71.266s ( 86.3 samples/s);
Processed 5000 samples
Finished Epoch[2 of 5]: [Training] loss = 0.408060 * 6149, metric = 10.07% * 6149 50.858s (120.9 samples/s);
Processed 5000 samples
Finished Epoch[3 of 5]: [Training] loss = 0.228304 * 6149, metric = 5.11% * 6149 50.589s (121.5 samples/s);
Processed 5000 samples
Finished Epoch[4 of 5]: [Training] loss = 0.154776 * 6149, metric = 3.04% * 6149 50.357s (122.1 samples/s);
Processed 5000 samples
Finished Epoch[5 of 5]: [Training] loss = 0.116543 * 6149, metric = 1.81% * 6149 50.841s (120.9 samples/s);
Stored trained model at .\temp\Output\FlowersTransferLearning.model
</pre></div></div>
</div>
</div>
<div class="section" id="Evaluate">
<h3>Evaluate<a class="headerlink" href="#Evaluate" title="Permalink to this headline">¶</a></h3>
<p>Evaluate the newly learnt flower classifier by transfering the learning
from a pre-trained ResNet model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Evaluate the test set</span>
<span class="n">predict_correct</span><span class="p">,</span> <span class="n">predict_total</span><span class="p">,</span> <span class="n">predict_accuracy</span> <span class="o">=</span> \
   <span class="n">eval_test_images</span><span class="p">(</span><span class="n">trained_model</span><span class="p">,</span> <span class="n">flowers_model</span><span class="p">[</span><span class="s1">&#39;results_file&#39;</span><span class="p">],</span> <span class="n">flowers_data</span><span class="p">[</span><span class="s1">&#39;testing_map&#39;</span><span class="p">],</span> <span class="n">base_model</span><span class="p">[</span><span class="s1">&#39;image_dims&#39;</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Done. Wrote output to </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">flowers_model</span><span class="p">[</span><span class="s1">&#39;results_file&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Evaluating model output node &#39;prediction&#39; for 300 images.
Processed 100 samples (79.00% correct)
Processed 200 samples (83.00% correct)
Processed 300 samples (84.33% correct)
253 of 300 prediction were correct
Done. Wrote output to .\temp\Output\FlowersPredictions.txt
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Test: Accuracy on flower data</span>
<span class="k">print</span> <span class="p">(</span><span class="s2">&quot;Prediction accuracy: {0:.2%}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">predict_correct</span><span class="p">)</span> <span class="o">/</span> <span class="n">predict_total</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Prediction accuracy: 84.33%
</pre></div></div>
</div>
</div>
<div class="section" id="With-much-smaller-dataset">
<h3>With much smaller dataset<a class="headerlink" href="#With-much-smaller-dataset" title="Permalink to this headline">¶</a></h3>
<p>With the Flowers dataset, we had hundreds of classes with hundreds of
images. What if we had a smaller set of classes and images to work with,
would transfer learning still work? Let us examine the Animals dataset
we have downloaded, consisting of nothing but sheep and wolves and a
much smaller set of images to work with (on the order of a dozen per
class). Let us take a look at a few…</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">sheep</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;738519_d0394de9.jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;Pair_of_Icelandic_Sheep.jpg&#39;</span><span class="p">]</span>
<span class="n">wolves</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;European_grey_wolf_in_Prague_zoo.jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;Wolf_je1-3.jpg&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;Sheep&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">sheep</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;Wolf&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">wolves</span><span class="p">]:</span>
    <span class="n">D</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;training_folder&#39;</span><span class="p">],</span> <span class="n">image</span><span class="p">),</span> <span class="n">width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_27_0.jpeg" src="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_27_0.jpeg" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_27_1.jpeg" src="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_27_1.jpeg" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_27_2.jpeg" src="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_27_2.jpeg" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_27_3.jpeg" src="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_27_3.jpeg" />
</div>
</div>
<p>The images are stored in <code class="docutils literal"><span class="pre">Train</span></code> and <code class="docutils literal"><span class="pre">Test</span></code> folders with the nested
folder giving the class name (i.e. <code class="docutils literal"><span class="pre">Sheep</span></code> and <code class="docutils literal"><span class="pre">Wolf</span></code> folders). This
is quite common, so it is useful to know how to convert that format into
one that can be used for constructing the mapping files CNTK expects.
<code class="docutils literal"><span class="pre">create_class_mapping_from_folder</span></code> looks at all nested folders in the
root and turns their names into labels, and returns this as an array
used by <code class="docutils literal"><span class="pre">create_map_file_from_folder</span></code>. That method walks those folders
and writes their paths and label indices into a <code class="docutils literal"><span class="pre">map.txt</span></code> file in the
root (e.g. <code class="docutils literal"><span class="pre">Train</span></code>, <code class="docutils literal"><span class="pre">Test</span></code>). Note the use of <code class="docutils literal"><span class="pre">abspath</span></code>, allowing
you to specify relative “root” paths to the method, and then move the
resulting map files or run from different directories without issue.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Set python version variable</span>
<span class="n">python_version</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="o">.</span><span class="n">major</span>

<span class="k">def</span> <span class="nf">create_map_file_from_folder</span><span class="p">(</span><span class="n">root_folder</span><span class="p">,</span> <span class="n">class_mapping</span><span class="p">,</span> <span class="n">include_unknown</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">valid_extensions</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;.jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;.jpeg&#39;</span><span class="p">,</span> <span class="s1">&#39;.png&#39;</span><span class="p">]):</span>
    <span class="n">map_file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_folder</span><span class="p">,</span> <span class="s2">&quot;map.txt&quot;</span><span class="p">)</span>

    <span class="n">map_file</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">if</span> <span class="n">python_version</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">map_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">map_file_name</span> <span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">map_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">map_file_name</span> <span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">class_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">class_mapping</span><span class="p">)):</span>
        <span class="n">folder</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_folder</span><span class="p">,</span> <span class="n">class_mapping</span><span class="p">[</span><span class="n">class_id</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
                <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">entry</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">filename</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">valid_extensions</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">map_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;{0}</span><span class="se">\t</span><span class="s2">{1}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">class_id</span><span class="p">))</span>
                    <span class="k">except</span> <span class="ne">UnicodeEncodeError</span><span class="p">:</span>
                        <span class="k">continue</span>

    <span class="k">if</span> <span class="n">include_unknown</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">root_folder</span><span class="p">):</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_folder</span><span class="p">,</span> <span class="n">entry</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">filename</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">valid_extensions</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">map_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;{0}</span><span class="se">\t</span><span class="s2">-1</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">filename</span><span class="p">))</span>
                <span class="k">except</span> <span class="ne">UnicodeEncodeError</span><span class="p">:</span>
                    <span class="k">continue</span>

    <span class="n">map_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">map_file_name</span>


<span class="k">def</span> <span class="nf">create_class_mapping_from_folder</span><span class="p">(</span><span class="n">root_folder</span><span class="p">):</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">directories</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">root_folder</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">directory</span> <span class="ow">in</span> <span class="n">directories</span><span class="p">:</span>
            <span class="n">classes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>

<span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;class_mapping&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_class_mapping_from_folder</span><span class="p">(</span><span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;training_folder&#39;</span><span class="p">])</span>
<span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;training_map&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_map_file_from_folder</span><span class="p">(</span><span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;training_folder&#39;</span><span class="p">],</span> <span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;class_mapping&#39;</span><span class="p">])</span>
<span class="c1"># Since the test data includes some birds, set include_unknown</span>
<span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;testing_map&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">create_map_file_from_folder</span><span class="p">(</span><span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;testing_folder&#39;</span><span class="p">],</span> <span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;class_mapping&#39;</span><span class="p">],</span>
                                                          <span class="n">include_unknown</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We can now train our model on our small domain and evaluate the results:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">animals_model</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;model_file&#39;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s1">&#39;AnimalsTransferLearning.model&#39;</span><span class="p">),</span>
    <span class="s1">&#39;results_file&#39;</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s1">&#39;AnimalsPredictions.txt&#39;</span><span class="p">),</span>
    <span class="s1">&#39;num_classes&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;class_mapping&#39;</span><span class="p">])</span>
<span class="p">}</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">animals_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">])</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">force_retraining</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Loading existing model from </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">animals_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">])</span>
    <span class="n">trained_model</span> <span class="o">=</span> <span class="n">C</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">animals_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">trained_model</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span>
                                <span class="n">animals_model</span><span class="p">[</span><span class="s1">&#39;num_classes&#39;</span><span class="p">],</span> <span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;training_map&#39;</span><span class="p">],</span>
                                <span class="n">learning_params</span><span class="p">)</span>
    <span class="n">trained_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">animals_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Stored trained model at </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">animals_model</span><span class="p">[</span><span class="s1">&#39;model_file&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Training transfer learning model for 5 epochs (epoch_size = 30).
Training 1026 parameters in 2 parameter tensors.
Finished Epoch[1 of 5]: [Training] loss = 1.559145 * 30, metric = 63.33% * 30 1.532s ( 19.6 samples/s);
Finished Epoch[2 of 5]: [Training] loss = 0.779069 * 30, metric = 36.67% * 30 20.450s (  1.5 samples/s);
Finished Epoch[3 of 5]: [Training] loss = 0.152882 * 30, metric = 3.33% * 30 0.032s (936.7 samples/s);
Finished Epoch[4 of 5]: [Training] loss = 0.018696 * 30, metric = 0.00% * 30 0.544s ( 55.1 samples/s);
Finished Epoch[5 of 5]: [Training] loss = 0.003499 * 30, metric = 0.00% * 30 0.553s ( 54.3 samples/s);
Stored trained model at .\temp\Output\AnimalsTransferLearning.model
</pre></div></div>
</div>
<p>Now that the model is trained for animals data. Lets us evaluate the
images.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># evaluate test images</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;testing_map&#39;</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">input_file</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">input_file</span><span class="p">:</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">img_file</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">true_label</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">eval_single_image</span><span class="p">(</span><span class="n">trained_model</span><span class="p">,</span> <span class="n">img_file</span><span class="p">,</span> <span class="n">base_model</span><span class="p">[</span><span class="s1">&#39;image_dims&#39;</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;None&#39;</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">class_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">probs</span><span class="p">,</span> <span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;class_mapping&#39;</span><span class="p">]))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">class_probs</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">:</span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">class_probs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="nb">float</span><span class="p">(</span><span class="n">class_probs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span> \
                                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">animals_model</span><span class="p">[</span><span class="s1">&#39;num_classes&#39;</span><span class="p">])])</span>
        <span class="n">true_class_name</span> <span class="o">=</span> <span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;class_mapping&#39;</span><span class="p">][</span><span class="n">true_label</span><span class="p">]</span> <span class="k">if</span> <span class="n">true_label</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;unknown&#39;</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Class: </span><span class="si">%s</span><span class="s1">, predictions: </span><span class="si">%s</span><span class="s1">, image: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">true_class_name</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">img_file</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Class: Sheep, predictions: Sheep:0.938 Wolf:0.062, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Sheep\Icelandic_breed_sheep.jpg
Class: Sheep, predictions: Sheep:0.999 Wolf:0.001, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Sheep\Icelandic_sheep_summer_06.jpg
Class: Sheep, predictions: Sheep:0.993 Wolf:0.007, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Sheep\Romney_sheep,_ewe_with_triplet_lambs_in_New_Zealand.jpg
Class: Sheep, predictions: Sheep:0.984 Wolf:0.016, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Sheep\Sheep,_Stodmarsh_6.jpg
Class: Sheep, predictions: Sheep:1.000 Wolf:0.000, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Sheep\Swaledale_sheep.jpg
Class: Wolf, predictions: Wolf:0.993 Sheep:0.007, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Wolf\9-wolf-profile-full.jpg
Class: Wolf, predictions: Wolf:0.999 Sheep:0.001, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Wolf\Canis_lupus_occidentalis.jpg
Class: Wolf, predictions: Wolf:0.987 Sheep:0.013, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Wolf\Iberian_Wolf.jpg
Could not open (skipping file):  C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Wolf\KolmÃ¥rden_Wolf.jpg
Class: Wolf, predictions: Wolf:0.891 Sheep:0.109, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Wolf\The_white_wolf_by_Lunchi.jpg
Class: unknown, predictions: Wolf:0.931 Sheep:0.069, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Bird_in_flight_wings_spread.jpg
Class: unknown, predictions: Wolf:0.751 Sheep:0.249, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\quetzal-bird.jpg
Class: unknown, predictions: Wolf:0.559 Sheep:0.441, image: C:\repos\CNTK\Examples\Image\DataSets\Animals\Test\Weaver_bird.jpg
</pre></div></div>
</div>
</div>
<div class="section" id="The-Known-Unknown">
<h3>The Known Unknown<a class="headerlink" href="#The-Known-Unknown" title="Permalink to this headline">¶</a></h3>
<p>Note the <code class="docutils literal"><span class="pre">include_unknown=True</span></code> in the <code class="docutils literal"><span class="pre">test_map_file</span></code> creation.
This is because we have a few unlabeled images in that directory - these
get tagged with label <code class="docutils literal"><span class="pre">-1</span></code>, which will never be matched by the
evaluator. This is just to show that if you train a classifier to only
find sheep and wolves, it will always find sheep and wolves. Showing it
pictures of birds like our unknown examples will only result in
confusion, as you can see above where the images of birds are falsely
predicted.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Bird_in_flight_wings_spread.jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;quetzal-bird.jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;Weaver_bird.jpg&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
    <span class="n">D</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">animals_data</span><span class="p">[</span><span class="s1">&#39;testing_folder&#39;</span><span class="p">],</span> <span class="n">image</span><span class="p">),</span> <span class="n">width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_35_0.jpeg" src="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_35_0.jpeg" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_35_1.jpeg" src="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_35_1.jpeg" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_35_2.jpeg" src="_images/CNTK_301_Image_Recognition_with_Deep_Transfer_Learning_35_2.jpeg" />
</div>
</div>
</div>
<div class="section" id="Final-Thoughts,-and-Caveats">
<h3>Final Thoughts, and Caveats<a class="headerlink" href="#Final-Thoughts,-and-Caveats" title="Permalink to this headline">¶</a></h3>
<p>Transfer Learning has limitations. If you noticed, we re-trained a model
that had been trained on ImageNet images. This meant it already <em>knew</em>
what “images” were, and had a good idea on concepts from low-level
(stripes, circles) to high-level (dog’s noses, cat’s ears). Re-training
such a model to detect sheep or wolves makes sense, but re-training it
to detect vehicles from aerial imagery would be more difficult. You can
still use Transfer Learning in these cases, but you might want to just
re-use earlier layers of the model (i.e. the early Convolutional layers
that have learned more primitive concepts), and you will likely require
much more training data.</p>
<p>Adding a catch-all category can be a good idea, but only if the training
data for that category contains images that are again sufficiently
similar to the images you expect at scoring time. As in the above
example, if we train a classifier with images of sheep and wolf and use
it to score an image of a bird, the classifier can still only assign a
sheep or wolf label, since it does not know any other categories. If we
were to add a catch-all category and add training images of birds to it
then the classifier might predict the class correctly for the bird
image. However, if we present it, e.g., an image of a car, it faces the
same problem as before as it knows only sheep, wolf and bird (which we
just happened to call called catch-all). Hence, your training data, even
for your catch-all, needs to cover sufficiently those concepts and
images that you expect later on at scoring time.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Cognitive Toolkit (CNTK) Team.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>